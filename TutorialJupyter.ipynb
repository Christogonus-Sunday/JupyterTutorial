{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Jupyter Notebooks\n",
    "\n",
    "#### Tutorial by Javier Sánchez, University of California, Irvine\n",
    "#### Prepared for the DESC Collaboration Meeting - Oxford - July 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements:**\n",
    " * anaconda (includes jupyter, astropy, numpy, scipy and matplotlib)\n",
    " * seaborn (pip install seaborn or conda install seaborn) \n",
    " * bokeh (pip install bokeh or conda install bokeh)\n",
    " * sklearn (pip install sklearn, conda install sklearn)\n",
    " * speclite (pip install speclite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jupyter](http://jupyter.org) creates an easy-to-read document that you can view in your web-browser with code (that runs and creates plots inside the document on the fly!) and text (with even math). The name \"Jupyter\" is a combination of Julia, Python, and R. However, it has support for over 40 programming languages. Jupyter is based on iPython notebooks, and, in fact you can still launch jupyter by typing ```ipython notebook``` on your terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept is similar to Mathematica and it works similarly (to run a **code cell** you can press ```shift+enter```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) How to launch Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can launch a Jupyter notebook by just typing ```jupyter notebook``` on your terminal and this will open a new tab or window on your default browser. You can also select a different browser by setting the environment variable ```$BROWSER``` to the path of the browser that you want to use before launching or using the ```--browser``` option in the command line. In Windows under \"Search programs and files\" from the Start menu, type ```jupyter notebook``` and select \"Jupyter notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Jupyter notebook is internally a [JSON document](http://json.org) but appears as a collection of \"cells\". Each segment of this document is a called cell. There are several types of cells but we are interested mainly in two types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Markdown cells**: Used for explanatory text (like this), and written in [GitHub-flavored markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). A markdown cells is usually displayed in output format, but a double click will switch it to input mode.  **Try that now on this cell.**  Use SHIFT+RETURN to toggle back to output format.  Markdown cells can contain latex math, for example:\n",
    "$$\n",
    "\\frac{d\\log G(z)}{d\\log a} \\simeq \\left[ \\frac{\\Omega_m (1 + z)^3}{\\Omega_m (1 + z)^3 + \\Omega_\\Lambda} \\right]^{0.55}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Code cells**: Contain executable source code in the language of the document’s associated kernel (usually python).  Use SHIFT+RETURN to execute the code in a cell and see its output directly below.  **Try that now for the code cell below**.  Note that the output is not editable and that each code cell has an associated label, e.g. `In [3]`, where the number records the order in which cells are executed (which is arbitrary since it depends on you).  **Re-run the code cell below and note that its number increases each time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info on notebooks and cells is [here](https://ipython.org/ipython-doc/3/notebook/nbformat.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Getting Started: Boilerplate and \"magic functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now focus on Python. To start a notebook it is a good practice to import all the packages and define the styles that we want to use in our \"boilerplate\". A good starting point is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these commands we set up our notebook to use the numpy package and the matplotlib package. If we use them like that, the plots will pop-up in a new window instead of being shown in the notebook. To see them in the notebook we should use a \"magic function\".\n",
    "\n",
    "There are two kinds of magics, line-oriented and cell-oriented. Line magics are prefixed with the % character and work much like OS command-line calls: they get as an argument the rest of the line, where arguments are passed without parentheses or quotes. Cell magics are prefixed with a double %%, and they are functions that get as an argument not only the rest of the line, but also the lines below it in a separate argument. A useful example is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic ```%pylab``` sets up the interactive namespace from numpy and matplotlib and ```inline``` adds the plots to the notebook. These plots are rendered in PNG format by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More useful magic commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * `%time` and `%timeit` measure execution time.\n",
    " * `%run` runs a Python script and loads all its data on the interactive namespace.\n",
    " * `%config InlineBackend.figure_formats = {'png', 'retina'}` Enables high-resolution PNG rendering and if we change `'png'` to `'svg'` or any other format we change the format of plots rendered within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic `%load` is really useful since it allows us to load any other Python script. It has an option ```-s``` that allows us to modify the code inside the notebook.  We use `%load` below to reveal solutions to some of the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line magic: You can run any system shell command using ```!``` before it. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced magic commands:\n",
    "\n",
    " * ```%load_ext Cython```\n",
    " * ```%cython``` or ```%%cython```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on \"magics\": \n",
    " * https://ipython.org/ipython-doc/3/interactive/magics.html\n",
    " * https://ipython.org/ipython-doc/3/interactive/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is a Python package that implements N-dimensional arrays objects and it is designed for scientific computing. It also implements a multitude of mathematical functions to operate efficiently with these arrays. The use of numpy arrays can significantly boost the performance of your Python script to be comparable to compiled C code. Some useful examples and tutorials can be found [here](http://www.scipy-lectures.org/intro/numpy/index.html) and [here](http://cs231n.github.io/python-numpy-tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example of how to compute the sum of two lists\n",
    "def add(x,y):\n",
    "    add=0\n",
    "    for element_x in x:\n",
    "        add=add+element_x\n",
    "    for element_y in y:\n",
    "        add=add+element_y\n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_list = range(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n10 sum_1=add(my_list,my_list) #I compute 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example using numpy arrays\n",
    "my_array = np.arange(0,100,1)\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n10 np.sum(my_array+my_array) #I compute 10 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement is especially significant when you have to use vectors or matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1: Compute the product element by element of a 2x2 list. Compare with numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%load ex1.py\n",
    "#my_list = [[1,2],[3,4]]\n",
    "#my_array=np.arange(1,5,1)\n",
    "#my_array=my_array.reshape(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful feature of numpy are masks and masked arrays. You can easily select all the values of a vector or an array that fulfill certain condition using a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In this example we will split a random array into three different categories taking advantage of the numpy masks\n",
    "#We generate an array with 1000 random elements in the interval [0,1)\n",
    "my_array = np.random.random(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time mask = [np.logical_and(my_array>i/3.,my_array<(i+1)/3.) for i in range(0,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(my_array[mask[0]]), len(my_array[mask[1]]), len(my_array[mask[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare to a traditional brute-force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is a very simple implementation. \n",
    "#Maybe sorting the list first or using a matrix instead of lists it would be faster\n",
    "%time #Use %%time for python2.x\n",
    "arr1=[]\n",
    "arr2=[]\n",
    "arr3=[]\n",
    "for element in my_array:\n",
    "    if(element>0 and element<1./3.):\n",
    "        arr1.append(element)\n",
    "    if(element>1./3. and element<2./3.):\n",
    "        arr2.append(element)\n",
    "    else:\n",
    "        arr3.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Matplotlib  (http://matplotlib.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most widespread package for plotting in Python. There are tons of examples on the web, and it is very well integrated in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let's plot a sinusoidal wave using matplotlib. (It is imported already since we used the magic ```%pylab inline```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we are going to set up the plots to be SVGs instead of the default PNGs\n",
    "\n",
    "### Uncomment this cell to use SVG\n",
    "\n",
    "#%config InlineBackend.figure_formats = {'svg',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We will sample the function in 100 points from 0 to pi\n",
    "x = np.linspace(0,np.pi,100)\n",
    "#We compute the sine of the numpy array x\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We make the plot (it automatically generates the figure)\n",
    "plt.plot(x,y,'-',color='green',label='$\\sin(x)$')\n",
    "#We add the label to the X and Y axes\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\sin(x)$')\n",
    "#We generate the legend\n",
    "plt.legend()\n",
    "#We change the limits of the X and Y axes\n",
    "plt.xlim(-0.05,np.pi+0.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Generate and plot a 2D histogram using matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ex2.py\n",
    "def ex2():\n",
    "    rs = np.random.RandomState(112)\n",
    "    x=np.linspace(0,10,11)\n",
    "    y=np.linspace(0,10,11)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    X=X.flatten()\n",
    "    Y=Y.flatten()\n",
    "    weights=np.random.random(len(X))\n",
    "    plt.hist2d(X,Y,weights=weights); #The semicolon here avoids that Jupyter shows the resulting arrays\n",
    "ex2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Seaborn (https://web.stanford.edu/~mwaskom/software/seaborn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn is a Python package based on matplotlib that includes some convenient plotting functions for statistical analysis. (Some people also like more its default style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First let's import seaborn (a warning will appear because it conflicts with %pylab inline)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning messages: Jupyter will output with a pink background all its warning messages. Most of them will tell us about deprecation or definition conflicts. The messages only appear the first time you run a cell that arises a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compare with matplotlib style (you can still use the same commands but they will render in seaborn style)\n",
    "#We make the plot (it automatically generates the figure)\n",
    "plt.plot(x,y,'-',color='green',label='$\\sin(x)$')\n",
    "#We add the label to the X and Y axes\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\sin(x)$')\n",
    "#We generate the legend\n",
    "plt.legend()\n",
    "#We change the limits of the X and Y axes\n",
    "plt.xlim(-0.05,np.pi+0.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Plot again your 2D histogram using seaborn jointplot (https://web.stanford.edu/~mwaskom/software/seaborn/examples/hexbin_marginals.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ex3.py\n",
    "def ex3():\n",
    "    rs = np.random.RandomState(112)\n",
    "    x=np.linspace(0,10,11)\n",
    "    y=np.linspace(0,10,11)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    X=X.flatten()\n",
    "    Y=Y.flatten()\n",
    "    weights=np.random.random(len(X))\n",
    "    sns.jointplot(X,Y,kind='hex',joint_kws={'C':weights}); #The semicolon here avoids that Jupyter shows the resulting arrays\n",
    "ex3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Bokeh (http://bokeh.pydata.org/en/latest/)\n",
    "\n",
    "Bokeh (apparently pronounced Boh-kay) is an interactive visualization tool in Python and it works very well within jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Bokeh modules for interactive plotting\n",
    "import bokeh.io\n",
    "import bokeh.mpl\n",
    "import bokeh.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's make an interactive plot from our sine wave example\n",
    "#We make the plot (it automatically generates the figure)\n",
    "plt.plot(x,y,'-',color='green',label='$\\sin(x)$')\n",
    "#We add the label to the X and Y axes\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\sin(x)$')\n",
    "#We generate the legend\n",
    "plt.legend()\n",
    "#We change the limits of the X and Y axes\n",
    "plt.xlim(-0.05,np.pi+0.05)\n",
    "plt.ylim(-0.05,1.05)\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we import interact to make an interactive plot\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Making an interactive plot with different probability distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are going to plot some probability distributions so we import scipy.stats\n",
    "from scipy import stats\n",
    "xd = np.linspace(0,10,100)\n",
    "dist = stats.norm(0,1)\n",
    "#We have to initialize the plot somehow so we choose a gaussian pdf\n",
    "yd=dist.pdf(xd)\n",
    "#pp is going to be the name of our plot\n",
    "pp = bokeh.plotting.figure(title=\"Probability distribution plot\", plot_height=300, plot_width=600, y_range=(0.05,1.05))\n",
    "#rr is going to be our line\n",
    "rr = pp.line(xd,yd,color=\"red\",line_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we make a function of 3 parameters, the name f that is going to be the type of pdf that we select\n",
    "#and par1, par2 that are the value of two parameters of these distributions (mean,sigma etc)\n",
    "def pdist(f,par1=0,par2=1):\n",
    "    if f==\"Gaussian\": dist = stats.norm(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Uniform\": dist = stats.uniform(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Binomial\": dist = stats.binom(par1,par2); rr.data_source.data['y']=dist.pmf(xd)\n",
    "    if f==\"Poisson\": dist = stats.poisson(par1); rr.data_source.data['y']=dist.pmf(xd)\n",
    "    if f==\"Cauchy\": dist = stats.cauchy(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Laplace\": dist = stats.laplace(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Chi2\": dist = stats.chi2(par1); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Student t\": dist = stats.t(par1); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Fisher f\": dist = stats.f(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Beta\": dist = stats.beta(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Gamma\": dist = stats.gamma(par1,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    if f==\"Weibull\": dist = stats.dweibull(par1,0,par2); rr.data_source.data['y']=dist.pdf(xd)\n",
    "    \n",
    "    bokeh.io.push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We show the plot using the bokeh.plotting.show command\n",
    "bokeh.plotting.show(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we make the interactive plot using the interact command\n",
    "#we specify the values of the parameters as lists or ranges\n",
    "interact(pdist,f=[\"Gaussian\",\"Uniform\",\"Binomial\",\"Poisson\",\"Cauchy\",\n",
    "                  \"Chi2\",\"Laplace\",\"Student t\",\"Fisher f\",\"Beta\",\"Gamma\",\"Weibull\"],par1=(0,10),par2=(0,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Optional exercise: Try to implement an interactive example with Bokeh**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Use interactive documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter also makes easier the use of new packages providing interactive documentation. The command ```help(name_of_the_package)``` lists the available documentation for a pacakge. ```?name``` provides information about the package. **shift+tab** provides the arguments to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(bokeh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test shift+tab\n",
    "pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Reading astronomical data (FITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of us have struggled a little while creating a FITS file using, for example, `cfitsio` (you have to initialize status and things like that). The syntax is also kind of obscure and you have to be sure of the format of the variables you are reading. Reading images or FITS tables using Python and Jupyter is much easier and intuitive (and it is not much slower)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are basically two ways of reading a fits file using ```astropy```:\n",
    "\n",
    " 1. Using ```astropy.io.fits```: The ```astropy.io.fits``` module (originally ```PyFITS```) is a “pure Python” FITS reader in that all the code for parsing the FITS file format is in Python, though Numpy is used to provide access to the FITS data. ```astropy.io.fits``` currently also accesses the CFITSIO to support the FITS Tile Compression convention, but this feature is optional. It does not use CFITSIO outside of reading compressed images.\n",
    " 2. Using ```astropy.table```: It uses internally ```astropy.io.fits``` it is very convenient for BinarytableHDU in FITS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*There exist other ways to read fits files using Python. For example, you can use the ```fitsio``` package (to install it do ```pip install fitsio```). This other package is faster and works better for large files than astropy, making it necessary when performance is a strong requirement or constrained. However, it doesn't work under Windows and it needs to have a C compiler installed. The ```fitsio``` interface is pretty similar to astropy.table but, it is not identical (some of the things learned here can be directly applied and some other cannot)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Reading and plotting an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to download a small image from the WeakLensingDeblending package, which simulates one CCD chip in LSST at full depth (http://weaklensingdeblending.readthedocs.io/en/latest/products.html). The data can be downloaded using the link in here: ftp://ftp.slac.stanford.edu/groups/desc/WL/LSST_i_trimmed.fits.gz or from this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to use ```astropy.io.fits``` to read the FITS file as an hdulist (that includes an image HDU and a BinaryTableHDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We import the package needed to read the file\n",
    "import astropy.io.fits as fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = './downloaded_data/LSST_i_trimmed.fits.gz'\n",
    "#We open the file and it gives us an hdulist\n",
    "hdulist = fits.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We can check what this hdulist has using print\n",
    "print(hdulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are going to see what is in the image, we use imshow and select a gray colormap\n",
    "#we also select a minimum of 0 in the colorbar (vmin) and a maximum of 250 (vmax)\n",
    "plt.imshow(hdulist[0].data,vmin=0,vmax=250,cmap='gray')\n",
    "#Show the colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use ```astropy.table``` to read the BinaryTableHDU. We could also read it using ```hdulist[1].data``` but let's make use of this nice package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing astropy.table\n",
    "import astropy.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading the table. In a multi-hdu file we can specify the hdu with read(path,hdu=num_hdu)\n",
    "table = astropy.table.Table.read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we show the contents of the table\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select any column by simply using ```table['NAME_OF_THE_COLUMN']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We print the purity column of the table\n",
    "print(table['purity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Make a histogram of the signal to noise `snr_iso` for different purity cuts (Hint: lookup the documentation for `np.hist` and make use of numpy masks)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ex4.py\n",
    "def ex4():\n",
    "    masks = [np.logical_and(table['purity']>i/4.,table['purity']<(i+1)/4.) for i in range(0,4)]\n",
    "    for i in range(0,4):\n",
    "        label = str(i/4.)+' < purity < '+str((i+1)/4.)\n",
    "        plt.hist(table['snr_iso'][masks[i]],range=(0,20),bins=40, label=label, alpha=0.5, normed=True)\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    for i in range(0,4):\n",
    "        label = str(i/4.)+' < purity < '+str((i+1)/4.)\n",
    "        plt.hist(table['snr_grpf'][masks[i]],range=(0,20),bins=40, label=label, alpha=0.5, normed=True)\n",
    "    plt.legend()\n",
    "ex4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Repeat that with ```snr_grpf```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) Using seaborn to create useful plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are going to use some columns of the table above to produce a useful pairplot\n",
    "#We make use of numpy masks!\n",
    "selection = np.empty(len(table['snr_grpf']),dtype='a20')\n",
    "mask_03 = table['purity']<=0.3\n",
    "mask_06 = np.logical_and(table['purity']>0.3,table['purity']<=0.6)\n",
    "mask_09 = np.logical_and(table['purity']>0.6,table['purity']<=0.9)\n",
    "mask_1 = table['purity']>0.9\n",
    "selection[mask_03]=\"purity<=0.3\"\n",
    "selection[mask_06]=\"0.3<purity<=0.6\"\n",
    "selection[mask_09]=\"0.6<purity<=0.9\"\n",
    "selection[mask_1]=\"purity>0.9\"\n",
    "#We require the values dg1 and dg2 to be finite in order that seaborn creates automatically the histograms\n",
    "masked_array = np.logical_not(np.logical_or(np.isinf(table['dg1_grp']),np.isinf(table['dg2_grp'])))\n",
    "#We are going to plot just 1000 points\n",
    "nobj=500\n",
    "#We will use certain columns of the table\n",
    "cols = [selection[masked_array][0:nobj],table['dg1_grp'][masked_array][0:nobj], \\\n",
    "        table['dg2_grp'][masked_array][0:nobj],table['e1'][masked_array][0:nobj], \\\n",
    "       table['e2'][masked_array][0:nobj]]\n",
    "new_table = astropy.table.Table(cols,names=('selection','dg1_grp','dg2_grp','e1','e2'))\n",
    "#Seaborn pairplot requires a pandas data frame\n",
    "df = new_table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We are going to check the correlations using heatmap\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Keep track of the units. Use astropy.units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is difficult to keep track of which units you are using when you write very long programs. This is simplified when you use astropy.units (http://docs.astropy.org/en/stable/units/). The package also handles equivalences and makes easy the unit conversion. It raises an error if you are operating with incompatible units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 10*u.km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.to(u.imperial.mile) + 10*u.Mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example where some units are assumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We read a quasar-catalog data table\n",
    "quasar_table = astropy.table.Table.read('./downloaded_data/quasar_table.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We import speclite to compute magnitudes\n",
    "import speclite\n",
    "sdss = speclite.filters.load_filters('sdss2010-*')\n",
    "#Spectrum of quasar #40\n",
    "wave = np.load('./downloaded_data/wave.npy') #No units included but units are Angstroms\n",
    "flux = np.load('./downloaded_data/flux.npy') #It comes without units but they're 1e-17 erg/cm**2/s/AA\n",
    "#We use get magnitudes to compute the magnitudes. If the units are not included, it assumes (erg/cm**2/s/AA, AA)<-(flux, wave)\n",
    "mags = sdss.get_ab_magnitudes(flux*1e-17*u.erg/u.cm**2/u.s/u.AA,wave*u.AA)\n",
    "#If we don't use the correct units...\n",
    "mags_wrong = sdss.get_ab_magnitudes(flux,wave)\n",
    "mags_boss = np.hstack(quasar_table['PSFMAG_%d' %f][40] for f in range(0,5))\n",
    "print mags\n",
    "print mags_boss\n",
    "print mags_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) A complete example: How to make a redshift fitter (photo-z) using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we are going to prepare a Boosted decision tree photo-z estimator\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#Prepare the training array\n",
    "mags = np.vstack([quasar_table['PSFMAG_%d' % f] for f in range(0,5)]).T\n",
    "z = quasar_table['Z_VI']\n",
    "print(len(z))\n",
    "#train on 20% of the points\n",
    "mag_train = mags[::5]\n",
    "z_train = z[::5]\n",
    "print(len(z_train))\n",
    "#test on 5% of the points\n",
    "mag_test = mags[::18]\n",
    "z_test = z[::18]\n",
    "#Set up the tree\n",
    "clf = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1,max_depth=3, random_state=0)\n",
    "#Train the tree\n",
    "clf.fit(mag_train, z_train)\n",
    "#Test it!\n",
    "z_fit_train = clf.predict(mag_train)\n",
    "z_fit = clf.predict(mag_test)\n",
    "#Compute rms in the training set and test set\n",
    "rms_train = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
    "rms_test = np.mean(np.sqrt((z_fit - z_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(z_test,z_fit, color='k', s=0.1)\n",
    "plt.plot([-0.1, 6], [-0.1, 6], ':k')\n",
    "plt.text(0.04, 5, \"rms = %.3f\" % (rms_test))\n",
    "plt.xlabel('$z_{true}$')\n",
    "plt.ylabel('$z_{fit}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Train and evaluate the performance of the tree using colors instead of the magnitudes themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ex6.py\n",
    "def ex6():\n",
    "    colors = np.vstack([quasar_table['PSFMAG_%d' % f]-quasar_table['PSFMAG_%d' % (f+1)] for f in range(0,4)]).T\n",
    "    color_train = colors[::5]\n",
    "    color_test = colors[::18]\n",
    "    clf.fit(color_train, z_train)\n",
    "    #Test it!\n",
    "    z_fit_train = clf.predict(color_train)\n",
    "    z_fit = clf.predict(color_test)\n",
    "    #Compute rms in the training set and test set\n",
    "    rms_train = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
    "    rms_test = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
    "    plt.scatter(z_test,z_fit, color='k', s=0.1)\n",
    "    plt.plot([-0.1, 6], [-0.1, 6], ':k')\n",
    "    plt.text(0.04, 5, \"rms = %.3f\" % (rms_test))\n",
    "    plt.xlabel('$z_{true}$')\n",
    "    plt.ylabel('$z_{fit}$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional exercise**: Create a nearest-neighbors estimator (KNN) using ```from sklearn.neighbors import KNeighborsRegressor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load opt_ex1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.b) Extra: Deep Neural Network photo-z (you need keras and theano or tensorflow for this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use a Recurrent Neural network, it may not be the optimal choice but, this is to illustrate how to set up the network. More on recurrent neural networks here: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional exercise**: Create your own Neural Network photo-z estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load opt_nn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Create a lognormal simulation and compute its correlation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use randomfield to create a gaussian random field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import randomfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time generator = randomfield.Generator(8, 128, 1024, grid_spacing_Mpc_h=1.0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta = generator.generate_delta_field(smoothing_length_Mpc_h=2.0, seed=123, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to calculate the correlation function in the direction of the line-of-sight:\n",
    "\n",
    "$$\\xi_{\\parallel}(r)=\\langle \\delta(r') \\delta(r+r')\\rangle$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Let's compute a simple version of the correlation function in the direction of the direction of the line-of-sight\n",
    "corr = np.zeros(delta.shape[2])\n",
    "for i in range(1,delta.shape[2]-1):\n",
    "    corr[i]=np.sum(delta[:,:,i:]*delta[:,:,:-i])/(delta.shape[0]*delta.shape[1]*(delta.shape[2]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = np.linspace(0,delta.shape[2],delta.shape[2]+1)\n",
    "plt.plot(r[1:-1],r[1:-1]**2*corr[1:])\n",
    "plt.xlim(0,200)\n",
    "plt.xlabel(r'$r_{\\parallel}$ [Mpc h$^{-1}$]')\n",
    "plt.ylabel(r'$r_{\\parallel}^{2}*\\xi_{\\parallel}(r_{\\parallel})$ [Mpc$^{2}$ h$^{-2}$]')\n",
    "plt.ylim(-4500,300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Create sky plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Healpy (http://healpy.readthedocs.io/en/latest/) includes tools for visualizing skymaps but, what if we want to use different projections? Or what if we cannot use healpy? See [here](https://github.com/dkirkby/bossdata/blob/master/examples/nb/MakingSkyPlots.ipynb), and [here](http://usersguidetotheuniverse.com/index.php/2011/03/03/whats-the-best-map-projection/) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_sky(ra, dec, data=None, nside=4, label='', projection='eck4', cmap=plt.get_cmap('jet'), norm=None,\n",
    "             hide_galactic_plane=False, healpy=False):\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    from matplotlib.collections import PolyCollection\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    ra=ra.to(u.deg).value\n",
    "    dec=dec.to(u.deg).value\n",
    "    if(healpy):\n",
    "        import healpy as hp\n",
    "        # get pixel area in degrees\n",
    "        pixel_area = hp.pixelfunc.nside2pixarea(nside, degrees=True)\n",
    "        # find healpixels associated with input vectors\n",
    "        pixels = hp.ang2pix(nside, 0.5*np.pi-np.radians(dec), np.radians(ra))\n",
    "        # find unique pixels\n",
    "        unique_pixels = np.unique(pixels)\n",
    "        # count number of points in each pixel\n",
    "        bincounts = np.bincount(pixels)\n",
    "        # if no data provided, show counts per sq degree\n",
    "        # otherwise, show mean per pixel\n",
    "        if data is None:\n",
    "            values = bincounts[unique_pixels]/pixel_area\n",
    "        else:\n",
    "            weighted_counts = np.bincount(pixels, weights=data)\n",
    "            values = weighted_counts[unique_pixels]/bincounts[unique_pixels]\n",
    "        # find pixel boundaries\n",
    "        corners = hp.boundaries(nside, unique_pixels, step=1)\n",
    "        corner_theta, corner_phi = hp.vec2ang(corners.transpose(0,2,1))\n",
    "        corner_ra, corner_dec = np.degrees(corner_phi), np.degrees(np.pi/2-corner_theta)\n",
    "        # set up basemap\n",
    "        m = Basemap(projection=projection, lon_0=-90, resolution='c', celestial=True)\n",
    "        m.drawmeridians(np.arange(0, 360, 30), labels=[0,0,1,0], labelstyle='+/-')\n",
    "        m.drawparallels(np.arange(-90, 90, 15), labels=[1,0,0,0], labelstyle='+/-')\n",
    "        m.drawmapboundary()\n",
    "        # convert sky coords to map coords \n",
    "        x,y = m(corner_ra, corner_dec)\n",
    "        # regroup into pixel corners\n",
    "        verts = np.array([x.reshape(-1,4), y.reshape(-1,4)]).transpose(1,2,0)\n",
    "        # Make the collection and add it to the plot.\n",
    "        coll = PolyCollection(verts, array=values, cmap=cmap, norm=norm, edgecolors='none')\n",
    "        plt.gca().add_collection(coll)\n",
    "        plt.gca().autoscale_view()\n",
    "        if not hide_galactic_plane:\n",
    "            # generate vector in galactic coordinates and convert to equatorial coordinates\n",
    "            galactic_l = np.linspace(0, 2*np.pi, 1000)\n",
    "            galactic_plane = SkyCoord(l=galactic_l*u.radian, b=np.zeros_like(galactic_l)*u.radian, frame='galactic').fk5\n",
    "            # project to map coordinates\n",
    "            galactic_x, galactic_y = m(galactic_plane.ra.degree, galactic_plane.dec.degree)\n",
    "            m.scatter(galactic_x, galactic_y, marker='.', s=2, c='k')\n",
    "        # Add a colorbar for the PolyCollection\n",
    "        plt.colorbar(coll, orientation='horizontal', pad=0.01, aspect=40, label=label)\n",
    "    else:\n",
    "        nx, ny = nside, nside\n",
    "\n",
    "        ra_bins = numpy.linspace(-180, 180, nx+1)\n",
    "        cth_bins = numpy.linspace(-1., 1., ny+1)\n",
    "        ra[ra>180]=ra[ra>180]-360\n",
    "        density, _, _ = numpy.histogram2d(ra, np.sin(dec*np.pi/180.), [ra_bins, cth_bins])\n",
    "        ra_bins_2d, cth_bins_2d = numpy.meshgrid(ra_bins, cth_bins)\n",
    "        m = Basemap(projection=projection, lon_0=0, resolution='l', celestial=True)\n",
    "        m.drawmeridians(np.arange(0, 360, 60), labels=[0,0,1,0], labelstyle='+/-')\n",
    "        m.drawparallels(np.arange(-90, 90, 15), labels=[1,0,0,0], labelstyle='+/-')\n",
    "        m.drawmapboundary()\n",
    "        xs, ys = m(ra_bins_2d, np.arcsin(cth_bins_2d)*180/np.pi)\n",
    "        pcm = plt.pcolormesh(xs, ys, density)\n",
    "        plt.colorbar(pcm,orientation='horizontal', pad=0.04, label=label)\n",
    "        if not hide_galactic_plane:\n",
    "            # generate vector in galactic coordinates and convert to equatorial coordinates\n",
    "            galactic_l = np.linspace(0, 2*np.pi, 1000)\n",
    "            galactic_plane = SkyCoord(l=galactic_l*u.radian, b=np.zeros_like(galactic_l)*u.radian, frame='galactic').fk5\n",
    "            # project to map coordinates\n",
    "            galactic_x, galactic_y = m(galactic_plane.ra.degree, galactic_plane.dec.degree)\n",
    "            m.scatter(galactic_x, galactic_y, marker='.', s=2, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ra = 360*np.random.random(10000)*u.deg\n",
    "dec = np.arcsin(-1+2*np.random.random(10000))*180/np.pi*u.deg\n",
    "plot_sky(ra,dec,healpy=False, nside=16, projection='eck4', label='Galaxies per pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Plot the positions of the quasars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ex7.py\n",
    "def ex7():\n",
    "    plot_sky(quasar_table['RA']*u.deg,quasar_table['DEC']*u.deg,nside=128, healpy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Using astropy.cosmology (http://docs.astropy.org/en/stable/cosmology/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "astropy.cosmology is a subpackage that contains several cosmologies implemented (LCDM, wCDM, etc) and computes some useful quantities for them such as: comoving distance, $H(z)$ or transverse separations from angular separations at redshift $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Using $\\Lambda CDM$ with Planck 2015 cosmological parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.cosmology import Planck15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Planck15.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z=np.logspace(-4,4,30)\n",
    "om=Planck15.Om(z)\n",
    "ob=Planck15.Ob(z)\n",
    "plt.plot(z,om,label=r'$\\Omega_{m}(z)$')\n",
    "plt.plot(z,ob,label=r'$\\Omega_{b}(z)$')\n",
    "plt.legend(loc=2)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\Omega(z)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h=Planck15.H(z)\n",
    "plt.plot(z,h,label=r'$H(z)$')\n",
    "plt.legend(loc=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$H(z)$ %s' % h.unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy.cosmology import z_at_value\n",
    "z_at_value(Planck15.comoving_distance, 1200 *u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy.cosmology import w0waCDM\n",
    "cosmo = w0waCDM(H0=75*u.km/u.s/u.Mpc,Om0=0.3,Ode0=0.7,w0=-1.2,wa=-3,Neff=4,Ob0=0.044,m_nu=1e-5*u.eV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_cosmo = cosmo.H(z)\n",
    "plt.plot(z,h_cosmo, label='Random cosmology')\n",
    "plt.plot(z,h, label='Planck15')\n",
    "plt.legend(loc=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$H(z)$ %s' % h.unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(z,h_cosmo/h-1)\n",
    "plt.legend(loc=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$H_{cosmo}(z)/H_{Planck15}(z)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
